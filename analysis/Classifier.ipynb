{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbf59d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a257c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['c47-34_29A', 'c47-34_29B'], ['c11-5_71A', 'c11-5_71B'], ['c79-97_86A', 'c79-97_86B'], ['c102-109_57A', 'c102-109_57B'], ['c56-68_0A', 'c56-68_0B'], ['c17-85_14A', 'c17-85_14B'], ['c83-101_100A', 'c83-101_100B'], ['c40-20_43A', 'c40-20_43B']]\n",
      "Classification Accuracyfor sub-01 & image pair 1: 0.5\n",
      "Classifier Evidence for sub-01 & image pair 1: 0.2751454984105615 0.7248545015894384\n",
      "Classification Accuracyfor sub-01 & image pair 2: 0.7\n",
      "Classifier Evidence for sub-01 & image pair 2: 0.6745141923953321 0.32548580760466805\n",
      "Classification Accuracyfor sub-01 & image pair 3: 0.6\n",
      "Classifier Evidence for sub-01 & image pair 3: 0.31797514307145935 0.6820248569285405\n",
      "Classification Accuracyfor sub-01 & image pair 4: 0.6\n",
      "Classifier Evidence for sub-01 & image pair 4: 0.25263726012934196 0.7473627398706582\n",
      "Classification Accuracyfor sub-01 & image pair 5: 0.8\n",
      "Classifier Evidence for sub-01 & image pair 5: 0.7765319382244134 0.2234680617755865\n",
      "Classification Accuracyfor sub-01 & image pair 6: 0.5\n",
      "Classifier Evidence for sub-01 & image pair 6: 0.5261094490561844 0.47389055094381555\n",
      "Classification Accuracyfor sub-01 & image pair 7: 0.4\n",
      "Classifier Evidence for sub-01 & image pair 7: 0.45788937443508815 0.5421106255649119\n",
      "Classification Accuracyfor sub-01 & image pair 8: 0.5\n",
      "Classifier Evidence for sub-01 & image pair 8: 0.4891226045920861 0.5108773954079139\n",
      "Classification Accuracyfor sub-02 & image pair 1: 0.6\n",
      "Classifier Evidence for sub-02 & image pair 1: 0.7495250691615032 0.25047493083849676\n",
      "Classification Accuracyfor sub-02 & image pair 2: 0.5\n",
      "Classifier Evidence for sub-02 & image pair 2: 0.6073289983831128 0.39267100161688717\n",
      "Classification Accuracyfor sub-02 & image pair 3: 0.6\n",
      "Classifier Evidence for sub-02 & image pair 3: 0.30911416407441505 0.690885835925585\n",
      "Classification Accuracyfor sub-02 & image pair 4: 0.3\n",
      "Classifier Evidence for sub-02 & image pair 4: 0.07265249980077673 0.9273475001992232\n",
      "Classification Accuracyfor sub-02 & image pair 5: 0.3\n",
      "Classifier Evidence for sub-02 & image pair 5: 0.49152654268286894 0.508473457317131\n",
      "Classification Accuracyfor sub-02 & image pair 6: 0.2\n",
      "Classifier Evidence for sub-02 & image pair 6: 0.29962175060555657 0.7003782493944435\n",
      "Classification Accuracyfor sub-02 & image pair 7: 0.5\n",
      "Classifier Evidence for sub-02 & image pair 7: 0.5004230064471991 0.499576993552801\n",
      "Classification Accuracyfor sub-02 & image pair 8: 0.5\n",
      "Classifier Evidence for sub-02 & image pair 8: 0.6597142047755551 0.34028579522444496\n",
      "Classification Accuracyfor sub-03 & image pair 1: 0.7\n",
      "Classifier Evidence for sub-03 & image pair 1: 0.3986314051083214 0.6013685948916786\n",
      "Classification Accuracyfor sub-03 & image pair 2: 0.5\n",
      "Classifier Evidence for sub-03 & image pair 2: 0.8048140805060872 0.19518591949391276\n",
      "Classification Accuracyfor sub-03 & image pair 3: 0.4\n",
      "Classifier Evidence for sub-03 & image pair 3: 0.533299725315896 0.4667002746841041\n",
      "Classification Accuracyfor sub-03 & image pair 4: 0.5\n",
      "Classifier Evidence for sub-03 & image pair 4: 0.3832722845517279 0.616727715448272\n",
      "Classification Accuracyfor sub-03 & image pair 5: 0.2\n",
      "Classifier Evidence for sub-03 & image pair 5: 0.3105878947331465 0.6894121052668535\n",
      "Classification Accuracyfor sub-03 & image pair 6: 0.6\n",
      "Classifier Evidence for sub-03 & image pair 6: 0.25225893678871025 0.7477410632112897\n",
      "Classification Accuracyfor sub-03 & image pair 7: 0.8\n",
      "Classifier Evidence for sub-03 & image pair 7: 0.4172770062104526 0.5827229937895473\n",
      "Classification Accuracyfor sub-03 & image pair 8: 0.6\n",
      "Classifier Evidence for sub-03 & image pair 8: 0.1983765538642568 0.8016234461357433\n",
      "Classification Accuracyfor sub-05 & image pair 1: 0.7\n",
      "Classifier Evidence for sub-05 & image pair 1: 0.9143534601542452 0.08564653984575471\n",
      "Classification Accuracyfor sub-05 & image pair 2: 0.5\n",
      "Classifier Evidence for sub-05 & image pair 2: 0.6664005411600588 0.3335994588399412\n",
      "Classification Accuracyfor sub-05 & image pair 3: 0.3\n",
      "Classifier Evidence for sub-05 & image pair 3: 0.4282362749882253 0.5717637250117746\n",
      "Classification Accuracyfor sub-05 & image pair 4: 0.4\n",
      "Classifier Evidence for sub-05 & image pair 4: 0.24773304905027888 0.7522669509497211\n",
      "Classification Accuracyfor sub-05 & image pair 5: 0.6\n",
      "Classifier Evidence for sub-05 & image pair 5: 0.407215743492704 0.5927842565072959\n",
      "Classification Accuracyfor sub-05 & image pair 6: 0.6\n",
      "Classifier Evidence for sub-05 & image pair 6: 0.6546093950132419 0.34539060498675805\n",
      "Classification Accuracyfor sub-05 & image pair 7: 0.6\n",
      "Classifier Evidence for sub-05 & image pair 7: 0.26246758057816816 0.7375324194218319\n",
      "Classification Accuracyfor sub-05 & image pair 8: 0.8\n",
      "Classifier Evidence for sub-05 & image pair 8: 0.6264001880467329 0.373599811953267\n",
      "Classification Accuracyfor sub-06 & image pair 1: 0.6\n",
      "Classifier Evidence for sub-06 & image pair 1: 0.7192610309703212 0.28073896902967865\n",
      "Classification Accuracyfor sub-06 & image pair 2: 0.5\n",
      "Classifier Evidence for sub-06 & image pair 2: 0.6758116164675583 0.3241883835324417\n",
      "Classification Accuracyfor sub-06 & image pair 3: 0.1\n",
      "Classifier Evidence for sub-06 & image pair 3: 0.22201080548446517 0.7779891945155348\n",
      "Classification Accuracyfor sub-06 & image pair 4: 0.6\n",
      "Classifier Evidence for sub-06 & image pair 4: 0.16822483866678245 0.8317751613332176\n",
      "Classification Accuracyfor sub-06 & image pair 5: 0.3\n",
      "Classifier Evidence for sub-06 & image pair 5: 0.37394935675593033 0.6260506432440697\n",
      "Classification Accuracyfor sub-06 & image pair 6: 0.4\n",
      "Classifier Evidence for sub-06 & image pair 6: 0.724763944155487 0.27523605584451305\n",
      "Classification Accuracyfor sub-06 & image pair 7: 0.9\n",
      "Classifier Evidence for sub-06 & image pair 7: 0.6387084449720412 0.36129155502795884\n",
      "Classification Accuracyfor sub-06 & image pair 8: 0.7\n",
      "Classifier Evidence for sub-06 & image pair 8: 0.7044548272038277 0.2955451727961723\n",
      "Classification Accuracyfor sub-07 & image pair 1: 0.5\n",
      "Classifier Evidence for sub-07 & image pair 1: 0.7247632851039028 0.27523671489609725\n",
      "Classification Accuracyfor sub-07 & image pair 2: 0.6\n",
      "Classifier Evidence for sub-07 & image pair 2: 0.8455957272530018 0.15440427274699814\n",
      "Classification Accuracyfor sub-07 & image pair 3: 0.4\n",
      "Classifier Evidence for sub-07 & image pair 3: 0.4029683146497879 0.5970316853502121\n",
      "Classification Accuracyfor sub-07 & image pair 4: 0.5\n",
      "Classifier Evidence for sub-07 & image pair 4: 0.41261313038792113 0.587386869612079\n",
      "Classification Accuracyfor sub-07 & image pair 5: 0.7\n",
      "Classifier Evidence for sub-07 & image pair 5: 0.6011304788640777 0.3988695211359223\n",
      "Classification Accuracyfor sub-07 & image pair 6: 0.4\n",
      "Classifier Evidence for sub-07 & image pair 6: 0.608285182958927 0.3917148170410729\n",
      "Classification Accuracyfor sub-07 & image pair 7: 0.4\n",
      "Classifier Evidence for sub-07 & image pair 7: 0.6694543201790955 0.3305456798209046\n",
      "Classification Accuracyfor sub-07 & image pair 8: 0.5\n",
      "Classifier Evidence for sub-07 & image pair 8: 0.49990461741982717 0.5000953825801728\n",
      "Classification Accuracyfor sub-10 & image pair 1: 0.3\n",
      "Classifier Evidence for sub-10 & image pair 1: 0.3364817578407412 0.6635182421592589\n",
      "Classification Accuracyfor sub-10 & image pair 2: 0.3\n",
      "Classifier Evidence for sub-10 & image pair 2: 0.2216663029741895 0.7783336970258106\n",
      "Classification Accuracyfor sub-10 & image pair 3: 0.4\n",
      "Classifier Evidence for sub-10 & image pair 3: 0.6086797295459837 0.39132027045401635\n",
      "Classification Accuracyfor sub-10 & image pair 4: 0.4\n",
      "Classifier Evidence for sub-10 & image pair 4: 0.3967728307296773 0.6032271692703227\n",
      "Classification Accuracyfor sub-10 & image pair 5: 0.6\n",
      "Classifier Evidence for sub-10 & image pair 5: 0.62335970784214 0.37664029215786005\n",
      "Classification Accuracyfor sub-10 & image pair 6: 0.4\n",
      "Classifier Evidence for sub-10 & image pair 6: 0.2138025152108181 0.7861974847891819\n",
      "Classification Accuracyfor sub-10 & image pair 7: 0.7\n",
      "Classifier Evidence for sub-10 & image pair 7: 0.6331944180938626 0.36680558190613743\n",
      "Classification Accuracyfor sub-10 & image pair 8: 0.4\n",
      "Classifier Evidence for sub-10 & image pair 8: 0.4620467931006334 0.5379532068993667\n",
      "Classification Accuracyfor sub-11 & image pair 1: 0.5\n",
      "Classifier Evidence for sub-11 & image pair 1: 0.8536392871162406 0.1463607128837593\n",
      "Classification Accuracyfor sub-11 & image pair 2: 0.5\n",
      "Classifier Evidence for sub-11 & image pair 2: 0.47074131252254936 0.5292586874774506\n",
      "Classification Accuracyfor sub-11 & image pair 3: 0.4\n",
      "Classifier Evidence for sub-11 & image pair 3: 0.14173901146033374 0.8582609885396663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracyfor sub-11 & image pair 4: 0.6\n",
      "Classifier Evidence for sub-11 & image pair 4: 0.22452501565413607 0.775474984345864\n",
      "Classification Accuracyfor sub-11 & image pair 5: 0.4\n",
      "Classifier Evidence for sub-11 & image pair 5: 0.8645815597455782 0.13541844025442187\n"
     ]
    }
   ],
   "source": [
    "def read_timeseries_data(subnum, dataloc=\"../tseries\", runtype=\"pair\", runnum=1):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "      subnum: subject ID\n",
    "      dataloc: location of timeseries and metadata\n",
    "      runtype: either paired or random, type of run in task\n",
    "      runnum: run number. Either 1 or 2 for random runs, or 1-6 for paired runs\n",
    "   \n",
    "    Returns:\n",
    "      df: timeseries dataframe\n",
    "    \"\"\"\n",
    "    fname = f\"{dataloc}/sub-{subnum}_task-{runtype}_run-{runnum}_space-fsLR_den-91k_bold_timeseries.tsv\"\n",
    "    data = pd.read_csv(fname, sep=\"\\t\")\n",
    "    return data\n",
    "\n",
    "def read_metadata(subnum, dataloc=\"../tseries\", runtype=\"pair\", runnum=1):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "      subnum: subject ID\n",
    "      dataloc: location of timeseries and metadata\n",
    "      runtype: either paired or random, type of run in task\n",
    "      runnum: run number. Either 1 or 2 for random runs, or 1-6 for paired runs\n",
    "    \n",
    "    Returns:\n",
    "      df: metadata dataframe  \n",
    "    \"\"\"\n",
    "    fname = f\"{dataloc}/sub-{subnum}_task-{runtype}_run-0{runnum}_events.tsv\"\n",
    "    data = pd.read_csv(fname, sep=\"\\t\")\n",
    "    return data\n",
    "\n",
    "def find_image_pairs(subnum=\"01\"):\n",
    "    \"\"\"\n",
    "    The current function finds the image pair ID's used throughout the visual statistical learning task\n",
    "    \n",
    "    Parameters:\n",
    "      subnum: subject ID\n",
    "      \n",
    "    Returns:\n",
    "      list: list of image pairs\n",
    "    \"\"\"\n",
    "    meta = read_metadata(subnum)\n",
    "    image_pairs = meta[\"trial_type\"].unique()\n",
    "    return image_pairs\n",
    "\n",
    "def reducing_metadata_pulling_timeseries(image_of_interest, dataloc=\"../tseries\", runtype=\"pair\", runnum=1, subnum=\"01\"):\n",
    "    \"\"\"\n",
    "    The current function outputs a dataframe for \n",
    "    \n",
    "    Parameters:\n",
    "      image_of_interest: image ID\n",
    "      dataloc: location of timeseries and metadata\n",
    "      runtype: either paired or random, type of run in task\n",
    "      subnum: subject ID\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    onsets = []\n",
    "    #making a weights dictionary, where:\n",
    "    ##if the time is 0: we don't need to weight anything out, hence 1\n",
    "    ##if the time is 0.5: we create a weighting that takes 2 thirds of the first TR and 1 third of the second\n",
    "    ##if the time is 1: we create a weighting that takes 1 third of the first TR and 2 thirds of the second\n",
    "    weights_dict = dict(zip([0, 0.5, 1], [[1], [2/3, 1/3], [1/3, 2/3]]))\n",
    "\n",
    "    meta = read_metadata(subnum, dataloc=dataloc, runtype=runtype, runnum=runnum)\n",
    "    tseries = read_timeseries_data(subnum, dataloc=dataloc, runtype=runtype, runnum=runnum)\n",
    "    img_rows = meta[meta['trial_type'] == image_of_interest]\n",
    "    onset_time = img_rows[\"onset\"].to_list()\n",
    "    appended_data = []\n",
    "    \n",
    "    for i in onset_time:\n",
    "        counter = 0\n",
    "        TR = (i/1.5) + 3\n",
    "        var = i%1.5 \n",
    "        TR = math.floor(TR)\n",
    "        rows = [TR] if var == 0 else [TR,TR+1]\n",
    "        weights = weights_dict[var]\n",
    "        for row, weight in zip(rows, weights):\n",
    "            trow = tseries.iloc[int(row)] * weight \n",
    "            trow = pd.DataFrame(trow).transpose()\n",
    "            TROW = trow if counter == 0 else pd.concat([TROW, trow])\n",
    "            counter += 1\n",
    "        TROW = TROW.sum(axis=0).to_frame().transpose()\n",
    "        appended_data.append(TROW)\n",
    "    appended_data = pd.concat(appended_data)\n",
    "    return appended_data\n",
    "\n",
    "def train_and_test(subnum, train=[[\"random\", 1], [\"pair\", 5]], test=[[\"pair\", 6]], images=[\"c11-5_71A\", \"c11-5_71B\"]):\n",
    "    appended_data = []\n",
    "    appended_labels = []\n",
    "    for runtype, runnum in train:\n",
    "        for image in images:\n",
    "            train_data = reducing_metadata_pulling_timeseries(image_of_interest = image, runnum=runnum, runtype=runtype, subnum=subnum)  \n",
    "            appended_data.append(train_data)\n",
    "            appended_labels.extend([image]*train_data.shape[0])\n",
    "            \n",
    "    appended_data = pd.concat(appended_data)\n",
    "\n",
    "    appended_data_test = []\n",
    "    appended_labels_test = []\n",
    "    for runtype, runnum in test:\n",
    "        for image in images:\n",
    "            test_data = reducing_metadata_pulling_timeseries(image_of_interest = image, runnum=runnum, runtype=runtype, subnum=subnum)  \n",
    "            appended_data_test.append(test_data)\n",
    "            appended_labels_test.extend([image]*test_data.shape[0])\n",
    "            \n",
    "    appended_data_test = pd.concat(appended_data_test)\n",
    "    return np.array(appended_data_test), np.array(appended_labels_test), np.array(appended_data), np.array(appended_labels)\n",
    "  \n",
    "def classifier():\n",
    "    \n",
    "    subid = ['01', '02', '03', '05', '06', '07', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '35', '36', '37']\n",
    "    image = find_image_pairs()\n",
    "    image = [[image[0], image[1]], [image[2], image[3]], [image[4], image[5]], [image[6], image[7]], [image[8], image[9]], [image[10], image[11]], [image[12], image[13]], [image[14], image[15]]]\n",
    "    print(image)\n",
    "    \n",
    "    for sub in subid:\n",
    "        for pos, i in enumerate(image):\n",
    "            TESTX, TESTY, TRAINX, TRAINY = train_and_test(sub, images=i)\n",
    "            clf.fit(TRAINX, TRAINY)\n",
    "            acc = clf.score(TESTX, TESTY)\n",
    "            x = clf.predict(TESTX)\n",
    "            y = clf.predict_proba(TESTX)\n",
    "            print(f\"Classification Accuracyfor sub-{sub} & image pair {pos+1}: {acc}\")\n",
    "            col1 = np.average(y[:5, :1])\n",
    "            col2 = np.average(y[:5, 1:])\n",
    "            print(f\"Classifier Evidence for sub-{sub} & image pair {pos+1}: {col1} {col2}\")\n",
    "\n",
    "classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aec3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each subject, for each image pair in the first and last learning runs, what is the classfiication accuracy (x), what is the classifer evidence (avergae of column 1 first 5, column 2 second 5)\n",
    "\n",
    "#For every subject\n",
    "##For each image pair in the first and last learning runs\n",
    "###What is the classification accuracy\n",
    "###What is the classifer evidence (avergae of column 1 first 5, column 2 second 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cabfc8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['c47-34_29A', 'c47-34_29B'], ['c11-5_71A', 'c11-5_71B'], ['c79-97_86A', 'c79-97_86B'], ['c102-109_57A', 'c102-109_57B'], ['c56-68_0A', 'c56-68_0B'], ['c17-85_14A', 'c17-85_14B'], ['c83-101_100A', 'c83-101_100B'], ['c40-20_43A', 'c40-20_43B']]\n"
     ]
    }
   ],
   "source": [
    "image = find_image_pairs()\n",
    "image = [[image[0], image[1]], [image[2], image[3]], [image[4], image[5]], [image[6], image[7]], [image[8], image[9]], [image[10], image[11]], [image[12], image[13]], [image[14], image[15]]]\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fa98fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c47-34_29A', 'c47-34_29B']\n",
      "1\n",
      "['c11-5_71A', 'c11-5_71B']\n",
      "2\n",
      "['c79-97_86A', 'c79-97_86B']\n",
      "3\n",
      "['c102-109_57A', 'c102-109_57B']\n",
      "4\n",
      "['c56-68_0A', 'c56-68_0B']\n",
      "5\n",
      "['c17-85_14A', 'c17-85_14B']\n",
      "6\n",
      "['c83-101_100A', 'c83-101_100B']\n",
      "7\n",
      "['c40-20_43A', 'c40-20_43B']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for pos, i in enumerate(image):\n",
    "    print(i)\n",
    "    print(pos+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, x in enumerate(xs):\n",
    "    print(idx, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92973736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf46614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4bf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dbff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7748f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521581f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dd2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1f163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d55ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981719b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be58c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df17660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827e067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c423ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9acbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d90fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422a5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e7c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5fcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9b79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caba91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e0f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a4f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3a918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08792a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e90c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43229a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f78db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9b444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cfa47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d2e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67c6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71607ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8c2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd6ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
